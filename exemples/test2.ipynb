{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-google-vertexai # Clui-ci ne fonctionne pas. Il fonctionne qu si l'on est dans le cloud.\n",
    "# !pip install --upgrade --quiet  langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "# from langchain_google_vertexai import VertexAIEmbeddings, ChatVertexAI, VertexAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dataiku\n",
    "# from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import os\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../src/translation\")\n",
    "sys.path.append(\"../src/utils\")\n",
    "sys.path.append(\"../src/embeddings\")\n",
    "\n",
    "\n",
    "from utils import split_liste\n",
    "from dataikugoogletranslation import DataikuGoogleTranslate\n",
    "from dataikugoogleembeddings import DataikuGoogleEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, GoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBnr6rozG3HmBM8F_ZY95qTLfCdAVZ9R_E\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GoogleGenerativeAI(model='gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I help you today? \\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current_project_datasets = dataiku.Dataset.list()\n",
    "current_project_datasets\n",
    "mydataset = dataiku.Dataset('test_dataframe')\n",
    "\n",
    "df = mydataset.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_limites = {\n",
    "    \"fr\" : 6000,\n",
    "    \"bg\":1500\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dataikugoogletranslation:Validated target language code: en\n"
     ]
    }
   ],
   "source": [
    "translation = DataikuGoogleTranslate(api_key=\"AIzaSyBnr6rozG3HmBM8F_ZY95qTLfCdAVZ9R_E\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dataikugoogletranslation:Starting translation of DataFrame.\n",
      "INFO:dataikugoogletranslation: data_.shape :(4, 6)\n",
      "INFO:utils:Texts successfully split into sub-lists.\n",
      "INFO:dataikugoogletranslation:Texts successfully translated.\n",
      "WARNING:utils:The text has 1359 tokens, which exceeds the limit of 1500 tokens. It is troncated to 1359 token\n",
      "WARNING:utils:The text has 1359 tokens, which exceeds the limit of 1500 tokens. It is troncated to 1359 token\n",
      "WARNING:utils:The text has 1331 tokens, which exceeds the limit of 1500 tokens. It is troncated to 1331 token\n",
      "INFO:utils:Texts successfully split into sub-lists.\n",
      "INFO:dataikugoogletranslation:Texts successfully translated.\n",
      "INFO:dataikugoogletranslation:Texts successfully translated.\n",
      "INFO:dataikugoogletranslation:Texts successfully translated.\n",
      "INFO:dataikugoogletranslation:Texts successfully translated.\n",
      "INFO:dataikugoogletranslation: data_.shape :(26, 6)\n",
      "INFO:utils:Texts successfully split into sub-lists.\n",
      "INFO:dataikugoogletranslation:Texts successfully translated.\n",
      "INFO:utils:Texts successfully split into sub-lists.\n",
      "INFO:dataikugoogletranslation:Texts successfully translated.\n",
      "INFO:dataikugoogletranslation:Texts successfully translated.\n",
      "INFO:dataikugoogletranslation:Texts successfully translated.\n",
      "INFO:dataikugoogletranslation:Texts successfully translated.\n",
      "INFO:dataikugoogletranslation:Texts successfully translated.\n",
      "INFO:dataikugoogletranslation:Texts successfully translated.\n",
      "INFO:dataikugoogletranslation:Texts successfully translated.\n",
      "INFO:dataikugoogletranslation:Texts successfully translated.\n",
      "INFO:dataikugoogletranslation:Texts successfully translated.\n",
      "INFO:dataikugoogletranslation:Texts successfully translated.\n",
      "INFO:dataikugoogletranslation:Translation of DataFrame completed.\n"
     ]
    }
   ],
   "source": [
    "trans_df = translation.translation(df, language_limits=language_limites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dates', 'titles', 'links', 'texts', 'lang', 'cat', 'translated_title', 'translated_text'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dataikugoogleembeddings:Successfully created embeddings model: models/text-embedding-004\n",
      "INFO:dataikugoogleembeddings:Initialized GoogleEmbeddings with model: models/text-embedding-004\n"
     ]
    }
   ],
   "source": [
    "dataiu_embeddings = DataikuGoogleEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(trans_df['translated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils:Texts successfully split into sub-lists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dataikugoogleembeddings:Successfully embedded the sentences.\n"
     ]
    }
   ],
   "source": [
    "dataiu_embeddings.fit_transform(sentences=texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 768)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiu_embeddings.embedded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00965619, -0.00678366, -0.06699345, ...,  0.00211622,\n",
       "         0.08906598, -0.03584593],\n",
       "       [-0.01067151,  0.00724582, -0.04636824, ..., -0.01149945,\n",
       "         0.09163832, -0.04455397],\n",
       "       [-0.01409939,  0.0007742 , -0.04777483, ..., -0.01328054,\n",
       "         0.08977258, -0.03101638],\n",
       "       ...,\n",
       "       [ 0.02082186,  0.0292801 , -0.01108648, ..., -0.03559981,\n",
       "         0.05294483, -0.06462204],\n",
       "       [-0.01375768, -0.00063935, -0.05311592, ..., -0.07086442,\n",
       "         0.03946825, -0.06682924],\n",
       "       [ 0.04382988,  0.02975564, -0.06845737, ...,  0.0354755 ,\n",
       "         0.05011157, -0.02301187]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiu_embeddings.embedded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Summarization :\n",
    "    \n",
    "    def __init__(self, model_name = 'gemini-1.5-flash', chain_type : str= 'refine'):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.__llm: GoogleGenerativeAI= GoogleGenerativeAI(model = model_name, temperature=0.0)\n",
    "        self.__chain_type : str = chain_type\n",
    "        self.__chain = load_summarize_chain(self.__llm, chain_type=self.__chain_type)\n",
    "        self.dataframe : pd.DataFrame = None\n",
    "    \n",
    "    \n",
    "        \n",
    "    def get_documents_from_dataframe(self,dataframe: pd.DataFrame, document: str='translated_text', chunk_size: int=1000, chunk_overlap: int=100) :\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        df_loader = DataFrameLoader(dataframe, page_content_column=document)\n",
    "        df_document = df_loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        docs = text_splitter.split_documents(df_document)\n",
    "        \n",
    "        return docs\n",
    "    \n",
    "    \n",
    "    def genearate_description(self, json_data: list[dict], dataframe: pd.DataFrame, max_output_tokens = 100, col_to_summarize: str = 'translated_text', chunk_size = 1000, chunk_overlap=100) -> list[dict]:\n",
    "\n",
    "        for index, item in enumerate(json_data):\n",
    "            urls = []\n",
    "            if item['relevant'] == 'yes':\n",
    "                print('yes')\n",
    "                urls += item['sources']\n",
    "                if 'sub_articles' in item.keys():\n",
    "                    for sub in item['sub_articles']:\n",
    "                        urls += sub['sources'] if len(sub) != 0 else []\n",
    "                        \n",
    "                df = dataframe.loc[dataframe['url'].isin(urls), :] \n",
    "                docs = self.get_documents_from_dataframe(datafarme = df, document = col_to_summarize, chunk_size= chunk_size, chunk_overlap= chunk_overlap)\n",
    "\n",
    "                result = self.__chain.invoke(docs)\n",
    "                result = re.sub(r'[#$].*?:|\\*|\\n|#', '', result)\n",
    "\n",
    "                json_data[index]['decription'] = result\n",
    "\n",
    "        \n",
    "\n",
    "    # ------------------------------- PROPERTIES --------------------------------------------------------------------------\n",
    "\n",
    "    @property\n",
    "    def chain_type(self) -> None:\n",
    "        return self.__chain_type\n",
    "\n",
    "    @chain_type.setter\n",
    "    def chain_type(chaine_type: str)-> None:\n",
    "        self.__chain_type = chaine_type\n",
    "\n",
    "    @property\n",
    "    def llm(self)-> GoogleGenerativeAI:\n",
    "        return self.__llm\n",
    "\n",
    "    @property\n",
    "    def chain(self):\n",
    "        return self.__chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediascreening",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
